{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XJgRv9qnjE2X"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = 'gz_grey_40/'\n",
    "N = 58095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(d):\n",
    "    \n",
    "    img = Image.open(d)\n",
    "    img.load()\n",
    "    data = np.asarray(img, dtype='int32')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gzdata = np.zeros((N, 40, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    d = dir_ + str(i+1) + '.jpg'\n",
    "    gzdata[i] = load_image(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58095, 40, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gzdata.max()\n",
    "gzdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0naUtYePjE3G"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58095, 40, 40)\n"
     ]
    }
   ],
   "source": [
    "mydata = gzdata\n",
    "print(np.shape(mydata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(mydata, train_size=0.7, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255.0, 255.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max(), X_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXRklEQVR4nO2dbahe1ZXH//9co4kxWuNLCOqoSBimyDQDEgqdD06tgyMD0QFLHSgZEPTDCBb6oaFfagcG/KB1PswgRBrMDJ12hLajDM5LkJZOoVitWOtbRwlqE2Our/FGTcxN1ny458rt86x1717Pebn3Zv9/cHnus+8+Z699zln3PM//rL0WzQxCiNOfNcttgBBiGOTsQlSCnF2ISpCzC1EJcnYhKkHOLkQltHJ2kjeQ/C3JV0ju6sooIUT3cNLn7CSnAPwfgOsBHADwJIBbzeyFRbYxkkX77+v5f+n4K4GVegwydkVjeftYs8a/93h9IxvWrl071nbWWWcVb3/8+PGxtlOnTrl9M2SOWdvzbmbuQT+jxT63A3jFzPYDAMkfANgBYDFnx7p160YNc/vOzs6OtUUH3dtHdJFNTU0VtUX7aHsiIru8uZ04caK4b2a8M87wT7vnbN5YfTn76LUxj+eA0bG58MILx9q2bt061vbJJ5+42+/fv3+s7dixY27fzLE5efJkUVvUHu03cy7afIy/BMDvFrw/0LQJIVYgbe7s3r/ssX8zJG8HcHvze4vhhBBtaOPsBwBctuD9pQDeGO1kZrsB7AaANWvWKBBfiGWijbM/CWArySsBHATwFQB/vdRGo99zuhA/vO/c0acI7/tqJAyVfneK5uDtN7LL63vmmWcW2xV9//OOTTRfj8x8PaKxvPMQaSeewLZx40a37+WXXz7WlvnO7vHCC74MVapxAP55z5yH6PyO7nexczOxs5vZLMk7Afw3gCkAe8zs+Un3J4TolzZ3dpjZYwAe68gWIUSPKIJOiEqQswtRCXJ2ISqh1Xf2SRhVC1MRQIF66SmdkbLr7SMTQRepoqVE8/XGyij3mWMT4c0tEyWWmYM3VkYhj6IAPeU+o3p7+81EAUZ4NkTbZ/qOspgarzu7EJUgZxeiEuTsQlSCnF2IShhcoBuli8UxGQHGIxI11q9fP9bmLa2Mllu2XaqYWdIbCVZ9EJ0zby15dG68uUXz9Y7jzMyM2/fgwYNF20fLVg8fPly0fUR0fjNCZyYcORW6XNxTCLGqkbMLUQlydiEqQc4uRCXI2YWohMHV+NHQ1EzIYaQ8eu2RCuwlsowozUraRQIOj0xSjWhebZMmZMKLvScC0VOCzHn3nnZEx3x6enqs7cMPPywe66OPPhpri9T4thljM08fMvuN0J1diEqQswtRCXJ2ISqh1Xd2kq8CmAFwEsCsmV3ThVFCiO7pQqD7MzN7u7RzXyWNRmm77hzwxRrP/miszLrztqKZVzWli/1m1qhnsvxmzk8mi6u3Jt7rG2Xu9dqj0FqPjFg7ZEkoQB/jhaiGts5uAP6H5K+ayi9CiBVK24/xXzCzN0heDGAfyZfM7GcLOyws/ySEWD5a3dnN7I3mdRrAjzFX2XW0z24zu8bMrlGtNyGWj4mdneQGkhvnfwfw5wCe68owIUS3tPkYvxnAj5u79RkA/tXM/muxDcwsTPQwStuEFF1QamuGTBbYLmpyZ8JlM6q3R9swz0xYavQpsTQjcBRe7M03k102k6wjos15WOzaaFPrbT+Az026vRBiWJb/9imEGAQ5uxCVIGcXohI4VPgqAJAsHqxtOaSV8JgvEz7qEYlInuAUrTH32jOZaPtav3/22WePtUVhqd5x8DLZAv7cvO2jY5sR3foKd20Tcjs7Owszcy8y3dmFqAQ5uxCVIGcXohLk7EJUgpxdiEoYXI0fqiZZF8q9pw57KnAmg6qXXAHwFdhIcfYSLEQ2ZOrNecp9JgFHJizVS7axbt06t28mWUdpoopMUo1MCGwXCn2b/UqNF0LI2YWoBTm7EJUgZxeiEgYt/0RyTATqKxtnRKZUVB9kwlq98lOALzhlBKuMbaWiXZZMyK9HRjTLnPO+Snllwo77Cq3VnV2ISpCzC1EJcnYhKkHOLkQlLCnQkdwD4C8BTJvZ1U3bJgD/BuAKAK8C+LKZvVcy4GjkUkYoyST+6wIvoqttiaNMwsmMmBeRqa/uRex5bdEcvCi+TNLMTHRl25rpQ5dpaiv8dSEcltzZHwJww0jbLgCPm9lWAI8374UQK5glnb2p8PLuSPMOAHub3/cCuKlju4QQHTPpc/bNZnYIAMzsUFP+yUXln4RYGfQeVGNmuwHsBoA1a9YMt8ROCPF7TKrGHya5BQCa1+nuTBJC9MGkd/ZHAewEcE/z+kjphpkSQaVkShxlstZG4aqjZBTnLlRgbx+Rku3NLVonX6rGd/FUpK+wZW8fmWvO2z5ak+/Rl8rfSVmppTqQ/D6AXwD4Q5IHSN6GOSe/nuTLAK5v3gshVjBL3tnN7NbgT9d1bIsQokcUQSdEJcjZhaiEQdezm1mxWJJJDJlJith2fXamrnhGhMqUacrMwesbCXR9lIqK8Mo/ZfYb2eUdBy/JZ2RrW4EuQ6YUWKm9iwl2urMLUQlydiEqQc4uRCXI2YWoBDm7EJUwqBoP9JPJNaNqZvj4449bjZ9Rt73QXC+LbLSP6ImAt48oDNjbr3e+ukik4I0Vqd5eezRf71x4faPt216fQ2Yq9ljsaZfu7EJUgpxdiEqQswtRCXJ2ISph8PJPpeGXXWT09MjUKz9x4sRYmyfAZMJaI3Fs/fr1Y22ZsNaor5chNwpVLc0kGwl0mRBn75hHJay89qivd34/+uijon5ALt/BSiBjm+7sQlSCnF2ISpCzC1EJcnYhKqEkB90ektMkn1vQdjfJgySfaX5u7NdMIURbSqTxhwD8I4B/Hmm/38zuzQzmqfGZDKqZLK5dZLEtzawa1U7zVPpMFthM6OV5553ntntq/DnnnOP29Z4UZOrKeUTz9RRyry2yIVKhvRDnttfHSlDjS6+FxWydtPyTEGKV0eY7+50kn20+5p/fmUVCiF6Y1NkfAHAVgG0ADgG4L+pI8naST5F8qq/SykKIpZnI2c3ssJmdNLNTAB4EsH2RvrvN7Bozu2YlfPcRolYmCpcluWW+iiuAmwE8t1j/SciEaWZEpIwQ5gl03qeTaHxP8MqE1kbr2Tds2DDWtmnTJrevJ8Z52wPla+qjOXjrzr3MrtF+Z2Zm3L5e2HKEd368cx6FLXvbHz161O3rHYdMaa3oevbEw9IcAot9el7S2ZvyT9cCuJDkAQDfAnAtyW0ADMCrAO4oskQIsWxMWv7puz3YIoToEUXQCVEJcnYhKkHOLkQlDF7rbVRZ7SJTaSZpQmn20S7wxoqUbE+djlRzL/lEFALrqfSbN292+55//nhslJdUI+KDDz4Ya3vvvffcvl57lFQjo8a3JVNXLlNzz7vOMzUCu0B3diEqQc4uRCXI2YWoBDm7EJWw7AJdhoz4EfXNhMt6oZ6Z7b32KAQ2I7qde+65Y22RmHfRRReNtV111VVu3yuvvHKszVsnH607f+2118baovBNbx/RsfFCWyMRyzs/XqhqFOLshfxGIbBts+lmwmUjlF1WCDGGnF2ISpCzC1EJcnYhKkHOLkQlDKrGZ8gonV7fSCHPhDhm6sJ5ZMJlPcU5Ch/1VPqor6fcb9myxe3rqfEXXHDBWNs777zjbv/uu+N5SaNz1jYkNDoPmUQVHt7ToigBR8Yu71rKhMtGTw9G272nCfPozi5EJcjZhagEObsQlVBS/ukykj8h+SLJ50ne1bRvIrmP5MvNq3LHC7GCKRHoZgF83cyeJrkRwK9I7gPwNwAeN7N7SO4CsAvAN7oyLBMCmyETtliatTaT3bYL4dDrG4XLemJeFIbriXxeqGhG0IzCo7326Dz0sRY8E2aaEWWj8TP7aCM4ty3/dMjMnm5+nwHwIoBLAOwAsLfpthfATUvtSwixfKRulSSvAPAnAJ4AsHk+d3zzenHXxgkhuqP4OTvJcwD8EMDXzOyD0o9BJG8HcPtk5gkhuqLozk5yLeYc/Xtm9qOm+TDJLc3ftwCY9rZdWP6pC4OFEJNRUhGGmCsK8aKZfWfBnx4FsBPAPc3rIyUDtinumFnnGwklmcg8L/LKsz8jHGZEqEzfaC24NzevhjngR8Z9+OGHY21vvfWWu72XRDJa++5FekXXhtceRYp50W6ZHArefDNE10JfRU1Hr4VW5Z8AfAHAVwH8huQzTds3MefkD5O8DcDrAG6ZxFghxDCUlH/6OYDoC/p13ZojhOgLRdAJUQlydiEqQc4uRCUMvp69NLS0rxI4fZCxNerbVp0+evSo29dbY+5lgQWAI0eOjLV5ar5X5ina79tvv+32nZmZGWuLlHtPYT9+/Ljb1zuOmScd3lhRdlmPTNbb6ClQF0+dPHRnF6IS5OxCVIKcXYhKkLMLUQmDCnQkx8SOTBhh22SPUXsmxNETRDJCWl9hk++//77b7tkbJVB88803x9o8eyMhzRPjPIEw2ke0X0+Mi8Jlvfl65zwSijNryT0y5Z8iMuHBGXRnF6IS5OxCVIKcXYhKkLMLUQlydiEqYVA13szGEglE5ZA8tTQTXpjJ8pkJcdy4ceNYW5Q4wrMrSo7ghWR6IaWAr06fd955bl9P4faSTAB+sg5PiY6UYW+sKHGEl0AjKtOUOb8enr1RSKp33UWhuZmnLZmnOJnQ2pJx5tGdXYhKkLMLUQlydiEqoU35p7tJHiT5TPNzY//mCiEmpU35JwC438zuLR2MZKrsziiRqNI2BDWyyRN2vLZIZMzM1dvvsWPHivtGNnhEfb12T6CLzoMnZEWhuZ5IGIlLnpgXCZ2l69kj0c0TGdetW+f29c5vF+HQbcqcLSbQlSScPARgvvLLDMn58k9CiFVEm/JPAHAnyWdJ7lEVVyFWNsXOPlr+CcADAK4CsA1zd/77gu1uJ/kUyaf6WvElhFiaics/mdlhMztpZqcAPAhgu7ftwvJPbb6vCyHaUaLGu+Wf5uu8NdwM4LnuzRNCdEWb8k+3ktwGwAC8CuCOkgFLlcZMeGEmG2cmDNcL9fTaMiG/ka2e8p6pVxeROTalROfBOzaZ0NpM/baor3fMvfOTSQYRHe/SRBnRPvrIoLzYp+c25Z8ea2GTEGJgFEEnRCXI2YWoBDm7EJUwePmn0sdvngjUV7hsJMB4tnrCThQS6olF0Vje3KK14JkMuRmh0yNzHjJZYDOhpm0z+nrnIcpBcPbZZ7vty02bENpP99GBHUKIVYCcXYhKkLMLUQlydiEqQc4uRCUMrsaPqqVd1Mby1NpM/bYIL8zS2z5KhJAJzc1kcfXsOnLkiNs3s/ioNLw3sstLMhEdGy+TbFR/zbMhSuzhXQte5t7ouHg2RE9bPDJPFIZGd3YhKkHOLkQlyNmFqAQ5uxCVMLhANypUZEJVIzKhhJ5QEoV/tl0H7ZEJa82IOpFg5R3HSAiL2keJjoEnxkUCnXccMuJWdM4827z9RuGybcN4I9qGdHch8OnOLkQlyNmFqAQ5uxCVUJJwch3JX5L8dVP+6dtN+yaS+0i+3Lwqb7wQKxguJRw02WU3mNnRJqX0zwHcBeCvALxrZveQ3AXgfDP7xhL7slFhpq1YBPhiTab2dSSaeQKdF00Vbe+VDYrmVVq2KLKrrXAIlEf8Rce2tFwWUF4LHvCPQ7TW39uHF0EXjeXZ6yXHjOgrUq5UyJ6dncWpU6dcdXvJO7vNcbR5u7b5MQA7AOxt2vcCuKnIaiHEslBaJGKqSSM9DWCfmT0BYHNTB26+HtzF/ZkphGhLkbM3lV+2AbgUwHaSV5cOsLD806RGCiHak1Ljzex9AD8FcAOAw/NVYZrX6WCbT8s/tbRVCNGCEjX+IpKfaX5fD+BLAF4C8CiAnU23nQAe6ctIIUR7SsJltwDYS3IKc/8cHjaz/yD5CwAPk7wNwOsAbikZsI9Krp5SmclEG/UtVaKj0F5PNc+s2c6o3hHePiLF2LPBszfzBCU6Npk14p5dkTrthcF6bdH43pr8IcNiAf+YlZYCW2z8kvJPz2KuJvto+zsArltqeyHEykARdEJUgpxdiEqQswtRCUuGy3bJ1NSUrV+/vqhvJtFhRtzyhJ1IcNqwYUPRfiOBL1MbPWOXJ+BEgpMnTmXKN3l2eWHAQC6M12vv4jh6lJaEAvz5Rmvy25KxIRIkR9s//vhjnDx5crJwWSHE6YGcXYhKkLMLUQlydiEqQc4uRCUMml3WzMZU2Cic0mv31N6ob6TgZjLReipsRo3PPOnIZIHtq29pwpAukld44Z+Z49U242tp+Gmf9JG1drFjqDu7EJUgZxeiEuTsQlSCnF2IShhcoBsN64xEt8xa8KwNJW1AeSmhSFBpK9BFeCJSVM7I65vJWpuZgydURuKldy4z2WUju0pDazPiWHTdZY5NprxX5pxl0J1diEqQswtRCXJ2ISqhTfmnu0keJPlM83Nj/+YKISalRKA7DuCLC8s/kfzP5m/3m9m9/ZknhOiKkoSTBsAr/zQRowpmJqw1UiQzam2m1lvpWBm1NqO6t613l6WPUNFovt6Tjsz4mRBl7zhmnqBET4wyT3YyNfP6ok35JwC4k+SzJPeoiqsQK5s25Z8eAHAVgG0ADgG4z9tW5Z+EWBlMXP7JzA43/wROAXgQwPZgG5V/EmIFMHH5p/k6bw03A3iuHxOFEF3QpvzTv5Dchjmx7lUAd5QMOCpURCLFiRMnxtqivm1LMmXCNPta7+zZmxHzMplZozmUCoKZ0M1on975zcw3WiffVvTKZKLNhE5n6Ou6a1P+6autRxdCDIYi6ISoBDm7EJUgZxeiEuTsQlTCoMkrgJziOsrQ4YWeYuwRKaVtE1Jk6CsstW3m3ijU9Nxzzx1rixJwZJ7MeEp2tN9SMmN1cY329cRHd3YhKkHOLkQlyNmFqAQ5uxCVMLhANyo+RMJSZj17RhTx9ttFGG6b8SMy84qEME+giwS20rlFoapeWGkUarpp06axtmgOx44dG2uLxFOvZFcmL4B3DKL5enRxjXq0ve4A3dmFqAY5uxCVIGcXohLk7EJUgpxdiEoYXI0fJVJKI2XWw1OXMwp720y0mScKUd+2amt0HD0bMplZPXU5Uqe9vtF5zCj3nl2jNQPn8dT4TFhr2/DiLsJl24RZLza+7uxCVIKcXYhKkLMLUQlydiEqgUOuESf5FoDXmrcXAnh7sMGHQ/NafZxOc7vczC7y/jCos//ewORTp2PhCM1r9XE6z20h+hgvRCXI2YWohOV09t3LOHafaF6rj9N5bp+ybN/ZhRDDoo/xQlTC4M5O8gaSvyX5CsldQ4/fJST3kJwm+dyCtk0k95F8uXk9fzltnASSl5H8CckXST5P8q6mfVXPjeQ6kr8k+etmXt9u2lf1vEoZ1NmbSrD/BOAvAHwWwK0kPzukDR3zEIAbRtp2AXjczLYCeLx5v9qYBfB1M/sjAJ8H8LfNeVrtczsO4Itm9jkA2wDcQPLzWP3zKmLoO/t2AK+Y2X4z+wTADwDsGNiGzjCznwF4d6R5B4C9ze97Adw0qFEdYGaHzOzp5vcZAC8CuASrfG42x9Hm7drmx7DK51XK0M5+CYDfLXh/oGk7ndhsZoeAOacBcPEy29MKkldgrmT3EzgN5kZyiuQzAKYB7DOz02JeJQzt7N5CXT0OWKGQPAfADwF8zcw+WG57usDMTprZNgCXAthO8urltmkohnb2AwAuW/D+UgBvDGxD3xwmuQUAmtfpZbZnIkiuxZyjf8/MftQ0nxZzAwAzex/ATzGnuZw281qMoZ39SQBbSV5J8kwAXwHw6MA29M2jAHY2v+8E8Mgy2jIRnEuV8l0AL5rZdxb8aVXPjeRFJD/T/L4ewJcAvIRVPq9SBg+qIXkjgH8AMAVgj5n9/aAGdAjJ7wO4FnOrpg4D+BaAfwfwMIA/APA6gFvMbFTEW9GQ/FMA/wvgNwDmczp9E3Pf21ft3Ej+MeYEuCnM3egeNrO/I3kBVvG8SlEEnRCVoAg6ISpBzi5EJcjZhagEObsQlSBnF6IS5OxCVIKcXYhKkLMLUQn/D79ZGKoU7wATAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((-1, 40, 40, 1))\n",
    "X_test = X_test.reshape((-1, 40, 40, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40666, 40, 40, 1), (17429, 40, 40, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "USu4kabFjE6m"
   },
   "source": [
    "## Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZz29I6OjE6o"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Reshape,Dropout,LeakyReLU,Flatten,BatchNormalization,Conv2D,Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4r56fjG6jE6v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "discriminator = Sequential()\n",
    "\n",
    "discriminator.add(Conv2D(6, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation='relu', input_shape=[40, 40, 1]))\n",
    "discriminator.add(Conv2D(12, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation='relu'))\n",
    "discriminator.add(Conv2D(24, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation='relu'))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(300, activation='relu', input_shape=[600]))\n",
    "discriminator.add(Dense(150, activation='relu'))\n",
    "discriminator.add(Dense(10, activation='relu'))\n",
    "discriminator.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 20, 20, 6)         60        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 12)        660       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 5, 24)          2616      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               180300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               45150     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 230,307\n",
      "Trainable params: 230,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yKLXj37gjE60"
   },
   "outputs": [],
   "source": [
    "# size of the input noise array to generate fake images from\n",
    "codings_size = 100\n",
    "\n",
    "generator = Sequential()\n",
    "generator.add(Dense(300,activation='relu', input_shape=[codings_size]))\n",
    "generator.add(Dense(5*5*24, activation='relu'))\n",
    "generator.add(Reshape([5, 5, 24]))\n",
    "generator.add(Conv2DTranspose(filters=12, kernel_size=3, strides=(2,2), padding='same', activation='relu'))\n",
    "generator.add(Conv2DTranspose(filters=6, kernel_size=3, strides=(2,2), padding='same', activation='relu'))\n",
    "generator.add(Conv2DTranspose(filters=1, kernel_size=3, strides=(2,2), padding='same', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 300)               30300     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 600)               180600    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 5, 5, 24)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 10, 10, 12)        2604      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 20, 20, 6)         654       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 40, 40, 1)         55        \n",
      "=================================================================\n",
      "Total params: 214,213\n",
      "Trainable params: 214,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "53Ifz44hjE67"
   },
   "outputs": [],
   "source": [
    "GAN = Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jg644gdbjE7B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FEHzbEGajE7F"
   },
   "outputs": [],
   "source": [
    "GAN.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2481,
     "status": "ok",
     "timestamp": 1593375604195,
     "user": {
      "displayName": "Lavanya Nemani",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhUctWJlHJijwyrsnm1hUMmFkd_Tp1P_WYgUCvn=s64",
      "userId": "10514035278662942864"
     },
     "user_tz": -120
    },
    "id": "obU1UjS4jE7L",
    "outputId": "c723065f-2e17-46cb-898b-5a7c3bf79f79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 300)               30300     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 600)               180600    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 5, 5, 24)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 10, 10, 12)        2604      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 20, 20, 6)         654       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 40, 40, 1)         55        \n",
      "=================================================================\n",
      "Total params: 214,213\n",
      "Trainable params: 214,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Generator\n",
    "GAN.layers[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1926,
     "status": "ok",
     "timestamp": 1593375609796,
     "user": {
      "displayName": "Lavanya Nemani",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhUctWJlHJijwyrsnm1hUMmFkd_Tp1P_WYgUCvn=s64",
      "userId": "10514035278662942864"
     },
     "user_tz": -120
    },
    "id": "CGjYTTjxjE7Q",
    "outputId": "b0aa3839-8eea-48e1-96fc-e497cb987cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 20, 20, 6)         60        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 12)        660       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 5, 24)          2616      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               180300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               45150     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "Total params: 460,614\n",
      "Trainable params: 230,307\n",
      "Non-trainable params: 230,307\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Discriminator\n",
    "GAN.layers[1].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q8MCvZn7jE7V"
   },
   "source": [
    "### Setting up Training Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Ak7A2oSjE7W"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2478,
     "status": "ok",
     "timestamp": 1593375616231,
     "user": {
      "displayName": "Lavanya Nemani",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhUctWJlHJijwyrsnm1hUMmFkd_Tp1P_WYgUCvn=s64",
      "userId": "10514035278662942864"
     },
     "user_tz": -120
    },
    "id": "sxSitChNjE7c",
    "outputId": "059864e9-2523-473a-b7c3-5b4b2869aa73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58095, 40, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "my_data = mydata\n",
    "my_data = my_data.reshape((-1, 40, 40, 1))\n",
    "print(np.shape(my_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n"
     ]
    }
   ],
   "source": [
    "n_batch = int(58095 / batch_size)\n",
    "print(n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batches = np.zeros((n_batch, batch_size, 40, 40, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_batch):\n",
    "    X_batches[i] = my_data[i*batch_size:(i+1)*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MRPOg2EtjE7w"
   },
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BsDPUi25jE70"
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11182438161427657125\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 17893009139374425685\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6136641,
     "status": "ok",
     "timestamp": 1593381768050,
     "user": {
      "displayName": "Lavanya Nemani",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhUctWJlHJijwyrsnm1hUMmFkd_Tp1P_WYgUCvn=s64",
      "userId": "10514035278662942864"
     },
     "user_tz": -120
    },
    "id": "UgtnjNiSjE71",
    "outputId": "782378a9-fdba-44a9-d834-dd52097fa46a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on Epoch 1\n",
      "\tCurrently on batch number 1 of 113\n",
      "\tCurrently on batch number 2 of 113\n",
      "\tCurrently on batch number 3 of 113\n",
      "\tCurrently on batch number 4 of 113\n",
      "\tCurrently on batch number 5 of 113\n",
      "\tCurrently on batch number 6 of 113\n",
      "\tCurrently on batch number 7 of 113\n",
      "\tCurrently on batch number 8 of 113\n",
      "\tCurrently on batch number 9 of 113\n",
      "\tCurrently on batch number 10 of 113\n",
      "\tCurrently on batch number 11 of 113\n",
      "\tCurrently on batch number 12 of 113\n",
      "\tCurrently on batch number 13 of 113\n",
      "\tCurrently on batch number 14 of 113\n",
      "\tCurrently on batch number 15 of 113\n",
      "\tCurrently on batch number 16 of 113\n",
      "\tCurrently on batch number 17 of 113\n",
      "\tCurrently on batch number 18 of 113\n",
      "\tCurrently on batch number 19 of 113\n",
      "\tCurrently on batch number 20 of 113\n",
      "\tCurrently on batch number 21 of 113\n",
      "\tCurrently on batch number 22 of 113\n",
      "\tCurrently on batch number 23 of 113\n",
      "\tCurrently on batch number 24 of 113\n",
      "\tCurrently on batch number 25 of 113\n",
      "\tCurrently on batch number 26 of 113\n",
      "\tCurrently on batch number 27 of 113\n",
      "\tCurrently on batch number 28 of 113\n",
      "\tCurrently on batch number 29 of 113\n",
      "\tCurrently on batch number 30 of 113\n",
      "\tCurrently on batch number 31 of 113\n",
      "\tCurrently on batch number 32 of 113\n",
      "\tCurrently on batch number 33 of 113\n",
      "\tCurrently on batch number 34 of 113\n",
      "\tCurrently on batch number 35 of 113\n",
      "\tCurrently on batch number 36 of 113\n",
      "\tCurrently on batch number 37 of 113\n",
      "\tCurrently on batch number 38 of 113\n",
      "\tCurrently on batch number 39 of 113\n",
      "\tCurrently on batch number 40 of 113\n",
      "\tCurrently on batch number 41 of 113\n",
      "\tCurrently on batch number 42 of 113\n",
      "\tCurrently on batch number 43 of 113\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-1e252f3be15d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TRAINING COMPLETE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3287\u001b[0m         \u001b[0mfeed_symbols\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_symbols\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m         session != self._session):\n\u001b[0;32m-> 3289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   3220\u001b[0m       \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3221\u001b[0m     \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3222\u001b[0;31m     \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3223\u001b[0m     \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3224\u001b[0m     \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \"\"\"\n\u001b[1;32m   1488\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1444\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m         self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1446\u001b[0;31m             session._session, options_ptr)\n\u001b[0m\u001b[1;32m   1447\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Grab the seprate components\n",
    "generator, discriminator = GAN.layers\n",
    "\n",
    "# For every epcoh\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print(f\"Currently on Epoch {epoch+1}\")\n",
    "    i = 0\n",
    "    \n",
    "    # For every batch in the dataset\n",
    "    for X_batch in X_batches:\n",
    "        \n",
    "        i=i+1\n",
    "        print(f\"\\tCurrently on batch number {i} of {n_batch}\")\n",
    "        \n",
    "        #####################################\n",
    "        ## TRAINING THE DISCRIMINATOR ######\n",
    "        ###################################\n",
    "        \n",
    "        # Create Noise\n",
    "        noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "        \n",
    "        # Generate numbers based just on noise input\n",
    "        gen_images = generator(noise)\n",
    "                \n",
    "        # Concatenate Generated Images against the Real Ones\n",
    "        # TO use tf.concat, the data types must match!\n",
    "        X_fake_vs_real = tf.concat([gen_images, X_batch], axis=0)\n",
    "        \n",
    "        # Targets set to zero for fake images and 1 for real images\n",
    "        y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "        \n",
    "        # This gets rid of a Keras warning\n",
    "        discriminator.trainable = True\n",
    "        \n",
    "        # Train the discriminator on this batch\n",
    "        discriminator.train_on_batch(X_fake_vs_real, y1)\n",
    "        \n",
    "        \n",
    "        #####################################\n",
    "        ## TRAINING THE GENERATOR     ######\n",
    "        ###################################\n",
    "        \n",
    "        # Create some noise\n",
    "        noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "        \n",
    "        # We want discriminator to belive that fake images are real\n",
    "        y2 = tf.constant([[1.]] * batch_size)\n",
    "        \n",
    "        # Avois a warning\n",
    "        discriminator.trainable = False\n",
    "        \n",
    "        GAN.train_on_batch(noise, y2)\n",
    "        \n",
    "print(\"TRAINING COMPLETE\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6119301,
     "status": "ok",
     "timestamp": 1593381768059,
     "user": {
      "displayName": "Lavanya Nemani",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhUctWJlHJijwyrsnm1hUMmFkd_Tp1P_WYgUCvn=s64",
      "userId": "10514035278662942864"
     },
     "user_tz": -120
    },
    "id": "55H1DorBjE76",
    "outputId": "221197a4-2e7c-4c91-9cfb-062d41d5bf0b"
   },
   "outputs": [],
   "source": [
    "noise = tf.random.normal(shape=[100, codings_size])\n",
    "plt.imshow(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6119499,
     "status": "ok",
     "timestamp": 1593381771833,
     "user": {
      "displayName": "Lavanya Nemani",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhUctWJlHJijwyrsnm1hUMmFkd_Tp1P_WYgUCvn=s64",
      "userId": "10514035278662942864"
     },
     "user_tz": -120
    },
    "id": "CcD3Ws66jE7-",
    "outputId": "8dcc7ee2-a43f-49eb-f4a4-ee2e85425aa9"
   },
   "outputs": [],
   "source": [
    "results = generator(noise)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(10., 10.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(10, 10),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, results.reshape((-1, 40, 40))):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan_isolated.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
